name: Evaluate model # example

on:
  workflow_call:
  
jobs:
  setup_infra: # register a new github ephemeral github runner (evaluation requires more powerful machine than the free ones) 
    runs-on: ubuntu-latest
    steps: 
      - name: Add self hosted runner
        uses: markov-ngz/dispatch-action@v.1.0.0
        with:
          token: ${{secrets.GH_TOKEN}}
          workflow_file: register.yml
          repository: markov-ngz/private-auto-github-runner
          variables: 'repository=markov-ngz/DEVIA_BLOC_2'
          
  evaluate_test_model:
    needs: setup_infra
    runs-on: self-hosted
    strategy:
      matrix:
        python-version: ["3.11.8"]
    steps: 
      - name: Checkout repository
        uses: actions/checkout@v4
  
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version}}
      
      - name: Install dependencies
        run : |
          python3 -m pip install --upgrade pip
          pip install -r requirements.txt
          
      - name: Download model and tokenizer
        run : | 
          python3 load_resources.py
          pwd
          ls -a
          ls model/
          ls tokenizer/
      - name: Evaluate model  # scores uploaded on S3 
        run: | 
          python3 main.py --only_evaluate

          
  destroy_infra:
    runs-on: ubuntu-latest
    needs: evaluate_test_model
    if:   needs.evaluate_model.result == 'success' || needs.evaluate_model.result == 'failure'
    steps: 
      - name: Destroy self hosted runner
        uses: markov-ngz/dispatch-action@v.1.0.0
        with:
          token: ${{secrets.GH_TOKEN}}
          workflow_file: register.yml
          repository: markov-ngz/private-auto-github-runner
